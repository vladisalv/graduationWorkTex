Параллельная реализация программы выполнена на С++ с использованием технологии параллельного программирования MPI и технологии CUDA-C для использования графических ускорителей Nvidia.

Параллельный алгоритм разрабатывался таким способом, чтобы выполнялись следующие условия:
- автономность каждого этапа вычислений
- возможность загрузки/сохранения данных на каждом этапе
- унифицированный доступ к ресурсам системы

В результате была разработана следующая структура классов:
рисунок диаграмма, где выделены сущности, вычислители, управляющие и шаблонные (описывают распределенные данные)

Общая структура классов разбивается на следующие части:
1. Классы-сущности, описывающие распределенные структуры данных.
2. Классы-вычислители, преобразующие классы-сущности в другие классы-сущности.
3. Управляющие классы MyMpi и GpuComputing, через которые осуществляется взаимодействие с mpi и cuda.
Более подробное описание всех классов можно посмотреть в Приложении А.

Общая схема работы программы выглядит следующим образом:
рисунок блок-схема этапов работы программы

Данная схема работы позволяет начать и завершить работу на любом этапе, ограничившись выполнением только нескольких этапов. Такая гибкость программы может быть очень полезна в случае, когда пользователь захочет посмотреть на результат работы программы при разных параметрах. Например, если интересно посмотреть на поведение программы при разном значении ерс, то достаточно один раз сохранить спектры и в дальнейшем запускать программу сразу с этапа построения гомологической матрицы.

В целом программа выполнена в виде набора библиотечных функций, поэтому если пользователю потребуется специфичная версия программы, то относительно просто и в кротчайшие сроки такая версия может быть реализована.


Для работы с вводом/выводом файлов использовался архитектурно-независимый интерфейс стандарта MPI-2. Архитектура приложения позволяет использовать множество форматов ввода/вывода. В частности, для загрузки/сохранения гомологической матрицы предусмотрено два формата: бинарный файл и bmp изображение.

Для повышения масштабируемости алгоритма использовались только ассинхронные операции передачи данных. Это позволило значительно снизить коммуникационные издержки, особенно на этапе построения гомологической матрицы где использовалась схема взаимодействия "all-to-all".

Для реализации этапа "склейки" повторов использовались односторонние коммуникации. Данная технология MPI позволяет задавать все параметры, относящиеся к пересылке данных, только на одной стороне, что значительно упростило его реализацию и повысило эффективность.


Выделение в отдельные классы взаимодействия с mpi и GPU устройством позволило при компиляции отключить возможности эти классов и иметь следующие варианты сборки:
- последовательная программа
- последовательная программа, использующая графические процессоры
- параллельная программа без использования графических процессоров
- параллельная программа с использованием графических процессоров
Данная возможность позволяет существенно расширить список вычислительных платформ на которых может работать программа. 


Для эффективной работы графических ускорителей использовались механим общей памяти и "набивка" данных. С помощью профиллировщика было достигнуто такое разбиение задачи на блоки, что было достигнуто оптимальное соотношение между occupancy (загруженность устройства) и размером используемой общей памяти. Все эти меры позволили значительно ускорить этап построения гомологической матрицы.

Для удобства работы с программой был разработан ряд графических интерфейсов. Стоит отметить, что так как работа программы не предполагает диалога с пользователем, то данные интерфейсы работают в пакетном режиме, т.е. задают параметры алгоритма, запускают выполнение основной программы и ждут результатов. Поэтому все графические интерфейсы базируются на мощном Command Line Interface, реализованном в основной программе. CLI следует стандарту Posix, поддерживает разбор коротких и длинных опций. Таким образом графические интерфейсы правильно формируют аргументную строку и запускают основную программу.

Реализованы следующие виды интерфейсов:
- графический интерфейс на основе кроссплатформенной библиотеки Qt. Данный вариант очень если программа будет работать на локальной машине.
- графический интерфейс на основе кроссплатформенной библиотеки Qt и кроссплатворменной библиотеки libssh2. Данный вариант позволяет запускать программу графического интерфейса на локальном компьютере пользователя и запускать основную программу на удаленном сервере.

еще интернет интерфейс и псевдографический


Общий объем кода (программа + GUI) составляет 6 тыс. строк кода.


На рисунках a, b, c представлены результаты работы системы для анализа поведения параллельных программ, разрабатываемой Матвеевым Владимиром в рамках спецсеминара “Суперкомпьютерная обработка данных с использованием нейросетей и эволюционных вычислений” под руководством Л.Н.Королева и Н.Н.Поповой. Система позволяет визуализировать трассу параллельной программы, на которой отображается появление коммуникационных событий исследуемой программы во времени. Также система позволяет просматривать различные коммуникационные матрицы, в данном случае, по суммарному размеру сообщений и суммарному времени передачи сообщений между процессами.
